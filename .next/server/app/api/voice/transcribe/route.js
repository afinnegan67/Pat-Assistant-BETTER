"use strict";(()=>{var e={};e.id=650,e.ids=[650],e.modules={399:e=>{e.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},517:e=>{e.exports=require("next/dist/compiled/next-server/app-route.runtime.prod.js")},2048:e=>{e.exports=require("fs")},9801:e=>{e.exports=require("os")},5315:e=>{e.exports=require("path")},7130:(e,t,r)=>{r.r(t),r.d(t,{originalPathname:()=>N,patchFetch:()=>T,requestAsyncStorage:()=>v,routeModule:()=>y,serverHooks:()=>C,staticGenerationAsyncStorage:()=>b});var o={};r.r(o),r.d(o,{POST:()=>k,PUT:()=>_});var n=r(9303),a=r(8716),i=r(670),s=r(7070),c=r(9313),d=r(2374),p=r(7997),l=r(1491),u=r(8618),m=r(5090);let w=`You are the transcript processor for Patrick's construction assistant. You analyze meeting transcripts and voice notes to extract:

1. TASKS: Action items, to-dos, things that need to be done
   - Include who mentioned it
   - Include any deadline mentioned
   - Include which project it relates to (if mentioned)

2. PROJECT KNOWLEDGE: Decisions made, information discussed, updates
   - Group by project
   - Keep chunks atomic (one fact/decision per chunk)
   - Include context for why the decision was made if available

3. NEW PROJECTS: Any new job sites or projects mentioned that don't exist

Be thorough but precise. Don't invent information not in the transcript.`;async function h(e,t){let r=(await (0,c.Yw)()).map(e=>e.name).join(", ");try{let{toolCalls:t}=await (0,d._4)({model:l.bt,tools:{extractFromTranscript:(0,p.w3)({description:"Extract tasks, knowledge, and new projects from the transcript",inputSchema:u.Bd})},toolChoice:{type:"tool",toolName:"extractFromTranscript"},system:w,prompt:`Existing projects: ${r||"None"}

Transcript:
${e}

Extract all tasks, knowledge, and new projects from this transcript. You MUST call the extractFromTranscript tool with your results.`}),o=t[0];if(!o||o.dynamic)throw Error("No tool call result received");return o.input}catch(e){return console.error("Transcript processing error:",e),{tasks:[],knowledge:[],new_projects:[]}}}async function f(e,t){let r=0,o=0,n=0,a=new Map;for(let t of e.new_projects){if(!t.name)continue;let e=await (0,c.ib)(t.name);if(e){a.set(t.name.toLowerCase(),e.id);continue}let r=await (0,c.$L)({name:t.name,client_name:t.client_name,project_type:t.project_type,status:"future"});a.set(t.name.toLowerCase(),r.id),n++}for(let t of e.tasks){if(!t.description)continue;let e=null;if(t.project_name){let r=await (0,c.ib)(t.project_name);e=r?.id||a.get(t.project_name.toLowerCase())||null}await (0,c.vr)({description:t.description,project_id:e,deadline:t.deadline,priority:t.priority||"medium"}),r++}for(let r of e.knowledge){if(!r.content)continue;let e=null;if(r.project_name){let t=await (0,c.ib)(r.project_name);e=t?.id||a.get(r.project_name.toLowerCase())||null}let n=null;try{n=await (0,m.C6)(r.content)}catch(e){console.error("Failed to generate embedding:",e)}await (0,c.tR)({project_id:e,content:r.content,embedding:n,source_type:"meeting",source_id:t}),o++}return{tasksCreated:r,knowledgeAdded:o,projectsCreated:n}}var g=r(2126);let j=process.env.ELEVENLABS_API_KEY;async function x(e){let t=new FormData;t.append("audio",new Blob([new Uint8Array(e)]),"recording.webm"),t.append("model_id","scribe_v1");let r=await fetch("https://api.elevenlabs.io/v1/speech-to-text",{method:"POST",headers:{"xi-api-key":j},body:t});if(!r.ok){let e=await r.text();throw Error(`Transcription failed: ${e}`)}let o=await r.json(),n=o.text.split(/\s+/).length;return{text:o.text,duration:Math.round(n/150*60)}}async function k(e){try{let t=await e.formData(),r=t.get("audio"),o=t.get("duration");if(!r)return s.NextResponse.json({error:"No audio file provided"},{status:400});let n=await r.arrayBuffer(),a=Buffer.from(n),{text:i,duration:d}=await x(a),p=o?parseInt(o,10):d,l=await (0,c.ME)({raw_content:i,duration_seconds:p,source:"webapp"}),u=await h(i,"webapp"),m=function(e){let t=[];return(e.new_projects.length>0&&t.push(`New projects to create: ${e.new_projects.map(e=>e.name).join(", ")}`),e.tasks.length>0&&(t.push(`Tasks to create (${e.tasks.length}):`),e.tasks.slice(0,5).forEach(e=>{let r=e.project_name?` [${e.project_name}]`:"";t.push(`  - ${e.description}${r}`)}),e.tasks.length>5&&t.push(`  ... and ${e.tasks.length-5} more`)),e.knowledge.length>0&&t.push(`Knowledge chunks to store: ${e.knowledge.length}`),0===t.length)?"Nothing to extract from this transcript.":t.join("\n")}(u);if(p>1800)return await (0,g._b)(`Processed ${Math.round(p/60)} minute recording.

${m}

Reply "confirm" to save this data, or "cancel" to discard.`),s.NextResponse.json({success:!0,transcriptId:l.id,summary:m,needsConfirmation:!0,message:"Long recording - awaiting confirmation"});let w=await f(u,l.id);await (0,c.$3)(l.id,m);let j=`Processed recording: ${w.tasksCreated} tasks created, ${w.knowledgeAdded} knowledge chunks stored${w.projectsCreated>0?`, ${w.projectsCreated} new projects`:""}.`;return await (0,g._b)(j),s.NextResponse.json({success:!0,transcriptId:l.id,summary:m,needsConfirmation:!1,tasksCreated:w.tasksCreated,knowledgeAdded:w.knowledgeAdded,projectsCreated:w.projectsCreated})}catch(e){console.error("Transcription error:",e);try{await (0,g._b)("Your nephew Aidan failed to build me correctly. Blame him not me. (Voice transcription failed)")}catch(e){console.error("Failed to send error notification:",e)}return s.NextResponse.json({error:"Transcription failed",details:e.message},{status:500})}}async function _(e){try{let{transcriptId:t,action:r}=await e.json();if(!t)return s.NextResponse.json({error:"No transcript ID provided"},{status:400});if("cancel"===r)return await (0,g._b)("Recording discarded."),s.NextResponse.json({success:!0,message:"Transcript discarded"});if("confirm"===r)return await (0,g._b)("Recording data saved."),s.NextResponse.json({success:!0,message:"Transcript committed"});return s.NextResponse.json({error:"Invalid action"},{status:400})}catch(e){return console.error("Confirmation error:",e),s.NextResponse.json({error:"Confirmation failed",details:e.message},{status:500})}}let y=new n.AppRouteRouteModule({definition:{kind:a.x.APP_ROUTE,page:"/api/voice/transcribe/route",pathname:"/api/voice/transcribe",filename:"route",bundlePath:"app/api/voice/transcribe/route"},resolvedPagePath:"C:\\Users\\aidan\\OneDrive\\Documents\\Pats Assitant Improved\\app\\api\\voice\\transcribe\\route.ts",nextConfigOutput:"",userland:o}),{requestAsyncStorage:v,staticGenerationAsyncStorage:b,serverHooks:C}=y,N="/api/voice/transcribe/route";function T(){return(0,i.patchFetch)({serverHooks:C,staticGenerationAsyncStorage:b})}}};var t=require("../../../../webpack-runtime.js");t.C(e);var r=e=>t(t.s=e),o=t.X(0,[276,460,562],()=>r(7130));module.exports=o})();